# =================================================================================================
#     General Setup
# =================================================================================================

import pandas as pd
import os, random

# Ensure min Snakemake version
snakemake.utils.min_version("5.7")

# Load config file
configfile: "config.yaml"

# Specify number of threads to use. Hardcoded for now - gets overwritten automatically
# if snakemake is called with less threads, so we can use a large value here.
num_threads = 24

# =================================================================================================
#     Data
# =================================================================================================

samples = pd.read_table(config["data"]["samples"], dtype=str).set_index(["sample"], drop=False)
# samples.index = samples.index.set_levels([i.astype(str) for i in samples.index.levels])  # enforce str in index
snakemake.utils.validate(samples, schema="samples.schema.yaml")

sample_names=list(set(samples.index.get_level_values("sample")))
populations=list(set(samples.population.unique()))
populations.sort()

if isinstance(config["data"]["chromosomes"], list):
    chromosome_names = [str(x) for x in config["data"]["chromosomes"]]
    chromosome_lengths = {}
elif isinstance(config["data"]["chromosomes"], dict):
    chromosome_names = list(str(x) for x in config["data"]["chromosomes"].keys())
    chromosome_lengths = {str(key): str(value) for key, value in config["data"]["chromosomes"].items()}
else:
    raise Exception("Invalid entry for data/chromosomes in config file.")

# Wildcard constraints: only allow sample names from the spreadsheet to be used
wildcard_constraints:
    sample="|".join(sample_names),
    population="|".join(populations),
    chromosome="|".join(chromosome_names)

# Get a shorthand for the output directory
out_dir = config["data"]["output_dir"]
if not out_dir.endswith("/"):
    out_dir += "/"

# If the vcf file does not contain the chromosome lengths in its header, we need to provide them
# manully. This is done by specifying them in the config file - see there for details.
# Here, we define a function that uses these lengths for the vcf2smc call if given.
def get_chromosome_length_string( chromosome ):
    if chromosome in chromosome_lengths:
        return "--length " + chromosome_lengths[chromosome]
    else:
        return ""

# Get the list of sample names (columns in the vcf file) that are assigned to a given population.
def get_population_samples( population ):
    # Python cannot handle returning list.sort() directly, so we need to store it here first...
    pops = list( samples['sample'].loc[ samples['population'] == population ])
    pops.sort()
    return pops

# Get the string listing a population name and its samples as expected by smc++ vcf2smc,
# in the format "pop:smp1,smp2,..."
def get_population_list_string( population ):
    return population + ":" + ",".join( get_population_samples( population ))

# For a given population, get k "distinguished individuals" to be used for the estimation algorithm.
def get_distinguished_individuals( population, k ):
    # Get samples and sort, so that we have stability in the choice over multiple runs
    samples = get_population_samples(population)
    samples.sort()
    k = min(k, len(samples))

    # Set random seed, again for stability, and return result.
    random.seed(1234)
    return random.sample(samples, k)

logger.info("==================================================================")
logger.info("Chromosomes: " + str(len(chromosome_names)))
logger.info("Populations: " + str(len(populations)))
for pop in populations:
    logger.info("  - " + pop + ": " + str(len(get_population_samples(pop))) + " samples")
logger.info("Total samples: " + str(len(sample_names)))
logger.info("==================================================================")
logger.info("")

# Make a triangular list of populations, where we do pop1/pop2, but not pop2/pop1
# so that we do not have double effort for the split time estimation
split_list = []
for i in range(len(populations)):
    for j in range(i+1, len(populations)):
        split_list.append( populations[i] + "." + populations[j] )
# print (split_list)

# =================================================================================================
#     Target
# =================================================================================================

rule all:
    input:
        # per population demographic history plots
        out_dir + "plot.csv",
        multiext( out_dir + "plot", ".pdf", ".svg", ".png"),

        # split time estimations for pairs of populations, without duplication due to flipped
        # positions (pop1/pop2, but not pop2/pop1), and without "diagonal" of the combinations
        # of populations (pop1/pop1)
        # expand(
        #     out_dir + "plot-split.{populations}.{ext}",
        #     populations = split_list,
        #     ext = [ "pdf", "svg", "png" ]
        # )

localrules: all

# =================================================================================================
#     Helper Rules
# =================================================================================================

rule vcf_index:
    input:
        "{prefix}.vcf.gz"
    output:
        "{prefix}.vcf.gz.tbi"
    params:
        # pass arguments to tabix (e.g. index a vcf)
        "-p vcf"
    log:
        "logs/{prefix}.vcf_index.log"
    wrapper:
        "0.55.1/bio/tabix"

# =================================================================================================
#     vcf_to_smc
# =================================================================================================

# The documentation of smc++ only states that we need to process each contig individually.
# They are vague on what to do with the individual populations, but from context and usage,
# it seems those have to also individually processed here...
# Also, each run picks a "distinguished individual", which is given to us here from downstream
# rules, that use a stable random choice from the available list of samples per population.
rule vcf_to_smc:
    input:
        vcf = config["data"]["vcf"],
        tbi = config["data"]["vcf"] + ".tbi"
    output:
        out_dir + "smc/{population}.{chromosome}.{dist_indiv}.smc.gz"
    params:
        # get the samples for the given population
        poplist = lambda wildcards: \
            get_population_list_string(wildcards.population),
        # get the length of the chromosome, if provided in the config
        chrlen = lambda wildcards: \
            get_chromosome_length_string(wildcards.chromosome),
        extra = config["params"]["smcpp_vcf2smc"]["extra"]
    container:
        "docker://terhorst/smcpp:latest"
    threads:
        num_threads
    log:
        "logs/vcf_to_smc/{population}.{chromosome}.{dist_indiv}.log"
    benchmark:
        "benchmarks/vcf_to_smc/{population}.{chromosome}.{dist_indiv}.txt"
    shell:
        "smc++ vcf2smc {input.vcf} {output} {wildcards.chromosome} {params.poplist} "
        "-d {wildcards.dist_indiv} {wildcards.dist_indiv} {params.chrlen} {params.extra} --cores {threads} > {log} 2>&1"

# =================================================================================================
#     estimate / cv
# =================================================================================================

# The documentation is realy unclear as to which files need to go into a single call of this function,
# but from context, it seems that we want all chromosomes and all their variants of "distinguished
# individuals" that we picked to be combined here. So let's do so. That whole call then is
# repeated for each of our populations, estimating their respective population size history.
rule estimate_cv:
    input:
        smc = lambda wildcards: \
            expand(
                out_dir + "smc/{{population}}.{chromosome}.{dist_indiv}.smc.gz",
                chromosome=chromosome_names,
                dist_indiv=get_distinguished_individuals(
                    wildcards.population,
                    config["params"]["smcpp"]["num_distinguished_individuals"]
                )
            )
    output:
        out_dir + "{population}/model.final.json"
    params:
        algorithm = config["params"]["smcpp_estimate_cv"]["algorithm"],
        mu = config["params"]["smcpp_estimate_cv"]["mutation_rate"],
        extra = config["params"]["smcpp_estimate_cv"]["extra"],
        out_dir = out_dir + "{population}"
    container:
        "docker://terhorst/smcpp:latest"
    threads:
        num_threads
    log:
        "logs/estimate_cv/{population}.log"
    benchmark:
        "benchmarks/estimate_cv/{population}.txt"
    shell:
        # "echo \"Population: {wildcards.population}\" > {log} 2>&1;"
        # "echo -e \"Input smc files: {input.smc}\\n\" >> {log} 2>&1;"
        "smc++ {params.algorithm} {params.extra} {params.mu} {input.smc} -o {params.out_dir} "
        "--cores {threads} >> {log} 2>&1"

# =================================================================================================
#     plot
# =================================================================================================

# Combine the population size history estimates of all populations into one plot.
rule plot:
    input:
        json = expand( out_dir + "{population}/model.final.json", population=populations)
    output:
        csv = out_dir + "plot.csv",
        pdf = out_dir + "plot.pdf",
        svg = out_dir + "plot.svg",
        png = out_dir + "plot.png",
    params:
        extra = config["params"]["smcpp_plot"]["extra"]
    container:
        "docker://terhorst/smcpp:latest"
    log:
        "logs/plot.log"
    shell:
        "smc++ plot {output.pdf} {input.json} --csv {params.extra} >  {log} 2>&1 ;"
        "smc++ plot {output.svg} {input.json}       {params.extra} >> {log} 2>&1 ;"
        "smc++ plot {output.png} {input.json}       {params.extra} >> {log} 2>&1"

# =================================================================================================
#     vcf_to_smc joint
# =================================================================================================

rule vcf_to_smc_joint:
    input:
        vcf = config["data"]["vcf"],
        tbi = config["data"]["vcf"] + ".tbi"
    output:
        out_dir + "smc_joint/{population1}.{population2}.{chromosome}.smc.gz"
    params:
        # get the samples for the given populations
        poplist1 = lambda wildcards: \
            get_population_list_string(wildcards.population1),
        poplist2 = lambda wildcards: \
            get_population_list_string(wildcards.population2),
        # get the length of the chromosome, if provided in the config
        chrlen = lambda wildcards: \
            get_chromosome_length_string(wildcards.chromosome),
        extra = config["params"]["smcpp_vcf2smc_joint"]["extra"]
    container:
        "docker://terhorst/smcpp:latest"
    threads:
        num_threads
    log:
        "logs/vcf_to_smc_joint/{population1}.{population2}.{chromosome}.log"
    benchmark:
        "benchmarks/vcf_to_smc_joint/{population1}.{population2}.{chromosome}.txt"
    shell:
        "smc++ vcf2smc {input.vcf} {output} {wildcards.chromosome} {params.poplist1} {params.poplist2} "
        "{params.chrlen} {params.extra} --cores {threads} > {log} 2>&1"

# =================================================================================================
#     split
# =================================================================================================

rule split:
    input:
        json1 = out_dir + "{population1}/model.final.json",
        json2 = out_dir + "{population2}/model.final.json",
        smc1 = expand(
            out_dir + "smc_joint/{{population1}}.{{population2}}.{chromosome}.smc.gz",
            chromosome=chromosome_names
        ),
        smc2 = expand(
            out_dir + "smc_joint/{{population2}}.{{population1}}.{chromosome}.smc.gz",
            chromosome=chromosome_names
        )
    output:
        out_dir + "{population1}.{population2}/model.final.json"
    params:
        out_dir = out_dir + "{population1}.{population2}"
    container:
        "docker://terhorst/smcpp:latest"
    log:
        "logs/split/{population1}.{population2}.log"
    shell:
        "smc++ split -o {params.out_dir} {input.json1} {input.json2} {input.smc1} {input.smc2} > {log} 2>&1"

# =================================================================================================
#     plot joint
# =================================================================================================

rule plot_joint:
    input:
        json = out_dir + "{population1}.{population2}/model.final.json"
    output:
        pdf = out_dir + "plot-split.{population1}.{population2}.pdf",
        svg = out_dir + "plot-split.{population1}.{population2}.svg",
        png = out_dir + "plot-split.{population1}.{population2}.png"
    params:
        extra = config["params"]["smcpp_plot"]["extra"]
    container:
        "docker://terhorst/smcpp:latest"
    log:
        "logs/plot_joint/{population1}.{population2}.log"
    shell:
        "smc++ plot {output.pdf} {input.json} {params.extra} >  {log} 2>&1 ;"
        "smc++ plot {output.svg} {input.json} {params.extra} >> {log} 2>&1 ;"
        "smc++ plot {output.png} {input.json} {params.extra} >> {log} 2>&1"
