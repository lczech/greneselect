# =================================================================================================
#     General Setup
# =================================================================================================

import pandas as pd
import os

# Ensure min Snakemake version
snakemake.utils.min_version("5.7")

# Load config file
configfile: "config.yaml"

# =================================================================================================
#     Data
# =================================================================================================

# We accept a simple bam file, a list of bam files, or a list of lists (which is a dict here),
# where each list is first merged into one large bam file.
samples = {}
if isinstance(config["data"]["samples"], str):
    samples["sample"] = [config["data"]["samples"]]
elif isinstance(config["data"]["samples"], list):
    samples["samples"] = config["data"]["samples"]
elif isinstance(config["data"]["samples"], dict):
    samples = config["data"]["samples"]
else:
    raise Exception("Invalid entry for data/samples in config file.")

# Get a shorthand for the output directory
out_dir = config["data"]["output_dir"]
if not out_dir.endswith("/"):
    out_dir += "/"

# bam_basenames = [ os.path.basename(bam) for bam in get_all_bams() ]

# =================================================================================================
#     Target
# =================================================================================================

rule all:
    input:
        expand(out_dir + "pool/{freq1}-{freq2}.samples", freq1=samples.keys(), freq2=samples.keys() )
        # expand( out_dir + "freq/{sample}.txt", sample=samples.keys() )

localrules: all

# =================================================================================================
#     merge bam files
# =================================================================================================

rule samtools_merge:
    input:
        lambda wildcards: samples[wildcards.sample]
    output:
        temp(out_dir + "merge/{sample}.bam")
    params:
        "" # optional additional parameters as string
    threads:  # Samtools takes additional threads through its option -@
        8     # This value - 1 will be sent to -@
    wrapper:
        "0.61.0/bio/samtools/merge"

# =================================================================================================
#     bamfreq
# =================================================================================================

rule bamfreq:
    input:
        out_dir + "merge/{sample}.bam"
    output:
        out_dir + "freq/{sample}.txt"
    params:
        extra = config["params"]["bamfreq"]["extra"]
    log:
        out_dir + "log/bamfreq-{sample}.log"
    shell:
        "{workflow.basedir}/bamfreq/freq {params.extra} {input} > {output} 2> {log}"

    # run:
        # for bam in input:
        #     out_file = "{params.out_prefix}" + os.path.basename(bam) + ".freq"
        #     shell( "tools/bamfreq/freq {params.extra} " + bam + " > " + out_file + " 2> {log}" )
        # "bamfreq {input} > {output} 2> {log}"

# =================================================================================================
#     grenepool
# =================================================================================================

rule grenepool:
    input:
        freq1 = out_dir + "freq/{freq1}.txt",
        freq2 = out_dir + "freq/{freq2}.txt"
    output:
        out = out_dir + "pool/{freq1}-{freq2}.samples"
    params:
        outname = out_dir + "pool/{freq1}-{freq2}"
    log:
        out_dir + "log/grenepool-{freq1}-{freq2}.log"
    shell:
        # grenepool exits with code 1, which usually is an error and is treated as such,
        # but were, we want to ignore this.
        "set +e ;"
        "{workflow.basedir}/grenepool/pool {params.outname} {input} > {log} 2>&1 ;"
        "exit 0"
